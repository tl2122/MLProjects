# -*- coding: utf-8 -*-
"""ForestCoverType.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DICtBPwYxxLCOC0Q6JZ_B1p42YXefxAn
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

# Commented out IPython magic to ensure Python compatibility.
# %ls -l MyDrive/MLData

import pandas as pd
import numpy  as np
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv("MyDrive/MLData/covtype.data.csv")

dataset.info()

dataset.head()

dataset.describe()

sns.countplot(x=dataset['Cover_Type'], label='Count')
plt.show()

#Splitting dataset
x = dataset.iloc[:,:-1].values
y = dataset.iloc[:,-1].values
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = \
  train_test_split(x,y,test_size=0.1,random_state=0)

len(x_train[0])

acc_table={}
#Random Forest Model
from sklearn.ensemble import RandomForestClassifier
class_rm = RandomForestClassifier(random_state=0, class_weight='balanced')
class_rm.fit(x_train,y_train)

#Metrics and Cross Validation
from sklearn.metrics import accuracy_score,\
  confusion_matrix, f1_score, precision_score,recall_score
y_pred = class_rm.predict(x_test)
acc  = accuracy_score (y_test,y_pred)
#f1   = f1_score       (y_test,y_pred)
#prec = precision_score(y_test,y_pred)
#rec  = recall_score   (y_test,y_pred)
acc_table['RandomForest']=acc

acc

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

cm

# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.
cm_df = pd.DataFrame(cm,index = range(7), 
                      columns = range(7))
#Plotting the confusion matrix
plt.figure(figsize=(5,4))
sns.heatmap(cm_df, annot=True)
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

fig, ax = plt.subplots()
ax.bar(np.arange(54),class_rm.feature_importances_)
ax.set_title("Feature vs Feature Importances")
plt.show()

dataset.columns[:-1]

#Gradient Boosted Decison Trees Model
#from sklearn.ensemble import GradientBoostingClassifier
#class_gb = GradientBoostingClassifier(random_state=0, n_estimators=20)
#class_gb.fit(x_train,y_train)
#--------------Long runtime----------
#Hist Gradient Boosted Decison Trees Model
from sklearn.tree import DecisionTreeClassifier
class_dt = DecisionTreeClassifier(random_state=0)
class_dt.fit(x_train,y_train)

y_pred = class_dt.predict(x_test)
acc  = accuracy_score (y_test,y_pred)
acc
acc_table['DecisionTree']=acc

from sklearn.neural_network import MLPClassifier
layers = [54,20,20]
class_mlp = MLPClassifier(random_state=0,hidden_layer_sizes=layers,
                          )
class_mlp.fit(x_train[::15],y_train[::15])

y_pred_train= class_mlp.predict(x_train)
y_pred_test = class_mlp.predict(x_test)
acc_ts = accuracy_score(y_test,y_pred_test)
acc_ts
acc_tr = accuracy_score(y_train,y_pred_train)
print("Accuracy Train: {:5f} Test {:5f}".format(acc_tr,acc_ts))
acc_table['NeuralNet']=acc_ts

from sklearn.ensemble import AdaBoostClassifier
class_adb = AdaBoostClassifier(random_state=0,base_estimator=class_dt)
class_adb.fit(x_train,y_train)

print(class_adb)
y_pred_train= class_adb.predict(x_train)
y_pred_test = class_adb.predict(x_test)
acc_ts = accuracy_score(y_test,y_pred_test)
acc_ts
acc_tr = accuracy_score(y_train,y_pred_train)
print("Accuracy Train: {:5f} Test {:5f}".format(acc_tr,acc_ts))
acc_table['AdaBoost']=acc_ts

acc_table
results = pd.DataFrame.from_dict(acc_table,orient='index',
                               columns=['Accuracy'] )

results

